{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "732a42d6",
   "metadata": {},
   "source": [
    "## Hosptial Mortality Classifcation\n",
    "this notebookes creates classifers that predict probablity that a patient died in the hospital based on lab values. It uses Phyisio Mimic III as a data source and uses the python evalML to evaluate classifers. m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae7ea522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_validate,  StratifiedKFold\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from evalml.automl import AutoMLSearch\n",
    "import evalml\n",
    "import os\n",
    "import re\n",
    "import mlflow\n",
    "from evalml.model_understanding.prediction_explanations import explain_predictions\n",
    "from mlflow.models.signature import infer_signature\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "MAX_MEMORY = \"12g\"\n",
    "data_dir = os.getenv('PHYSIO_HOME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a9bf6",
   "metadata": {},
   "source": [
    "#### Data Loading\n",
    "Data is loaded from Phyiso MimiIII amd saved as paquet to pyspark data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7532a1cf",
   "metadata": {},
   "source": [
    "#### Data Egneineering \n",
    "creates a features data frame using max and min lab values during hospital stays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "212932f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/08/02 07:28:22 WARN Utils: Your hostname, themachine resolves to a loopback address: 127.0.1.1; using 192.168.0.17 instead (on interface wls6)\n",
      "21/08/02 07:28:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.0.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/08/02 07:28:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "org.apache.spark.api.python.PythonUtils.getPythonAuthSocketTimeout does not exist in the JVM",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7679/1270134951.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# reads all the csvs and writes them to parquet filesspark = SparkSession.builder \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HostpitalMortalityClassifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.executor.memory\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_MEMORY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.driver.memory\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_MEMORY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/musc/featureselectionresearch/ml_venv/lib/python3.8/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m                             \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                         \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                     \u001b[0;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                     \u001b[0;31m# by all sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/musc/featureselectionresearch/ml_venv/lib/python3.8/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/musc/featureselectionresearch/ml_venv/lib/python3.8/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n\u001b[0m\u001b[1;32m    147\u001b[0m                           conf, jsc, profiler_cls)\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/musc/featureselectionresearch/ml_venv/lib/python3.8/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encryption_enabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misEncryptionEnabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SPARK_AUTH_SOCKET_TIMEOUT\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPythonAuthSocketTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SPARK_BUFFER_SIZE\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetSparkBufferSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/musc/featureselectionresearch/ml_venv/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1528\u001b[0m                     answer, self._gateway_client, self._fqn, name)\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1530\u001b[0;31m             raise Py4JError(\n\u001b[0m\u001b[1;32m   1531\u001b[0m                 \"{0}.{1} does not exist in the JVM\".format(self._fqn, name))\n\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: org.apache.spark.api.python.PythonUtils.getPythonAuthSocketTimeout does not exist in the JVM"
     ]
    }
   ],
   "source": [
    "# reads all the csvs and writes them to parquet filesspark = SparkSession.builder \\\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HostpitalMortalityClassifier\") \\\n",
    "    .config(\"spark.executor.memory\", MAX_MEMORY) \\\n",
    "    .config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "LABEVENTS =  spark.read.parquet(data_dir + '/LABEVENTS.parquet')\n",
    "D_LABITEMS =  spark.read.parquet(data_dir + '/D_LABITEMS.parquet')\n",
    "ADMISSIONS =   spark.read.parquet(data_dir + '/ADMISSIONS.parquet')\n",
    "\n",
    "\n",
    "# sets the number of features to section by frequency\n",
    "n_features = 100\n",
    "\n",
    "# gets the top n_features most frequent features \n",
    "top_features = LABEVENTS\\\n",
    "                .join(D_LABITEMS, on = 'ITEMID', how='inner')\\\n",
    "                .dropna(subset=['VALUENUM'])\\\n",
    "                .groupby('LABEL')\\\n",
    "                .count().sort('count', ascending=False)\\\n",
    "                .limit(n_features).drop('count')\n",
    "\n",
    "\n",
    "## Data Transformations \n",
    "## gets the max and min value from the top n_features\n",
    "## groups by hospital admit id\n",
    "## creates a flag where the patient died \"Expired\" in the hosptial                                        \n",
    "data = LABEVENTS\\\n",
    ".join(D_LABITEMS, on = 'ITEMID', how='inner')\\\n",
    ".join(top_features, on='label', how='inner')\\\n",
    ".dropna(subset=['VALUENUM'])\\\n",
    ".groupby('HADM_ID')\\\n",
    ".pivot('LABEL')\\\n",
    ".agg(max('VALUENUM').alias('max'), min('VALUENUM').alias('min'))\\\n",
    ".join(ADMISSIONS.select('HADM_ID', col('HOSPITAL_EXPIRE_FLAG').alias('label')), on='HADM_ID', how='inner')\\\n",
    ".filter('label in (0,1)')\n",
    "\n",
    "## data Extraction to Pandas\n",
    "df = data.toPandas().set_index('HADM_ID')\n",
    "\n",
    "## create arrays for training model \n",
    "y = df.loc[:, 'label'].values\n",
    "X = df.drop('label', axis=1).values\n",
    "\n",
    "n_rows = X.shape[0]\n",
    "n_features = X.shape[1]\n",
    "feature_names_all = np.array(list(df.drop('label', axis=1).columns))\n",
    "label_prob = y.mean()\n",
    "print(F' n_rows: {n_rows}, n_features: {n_features}, label_prob {np.round(label_prob , 3)}')\n",
    "print(F'features: {feature_names_all}')\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2521b24",
   "metadata": {},
   "source": [
    "#### Basic Data Statics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48138e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stats_path = 'data_stats.csv'\n",
    "data_stats = df.describe()\n",
    "data_stats.to_csv(data_stats_path)\n",
    "data_stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6754a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "help(RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b4546",
   "metadata": {},
   "source": [
    "#### Data Splitting\n",
    "Data splitting via Statified Shuffle Split\n",
    "\n",
    "#### Feature Selection pyImpetous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562dfc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splitter = StratifiedKFold(shuffle=True)\n",
    "train_index, test_index = next(splitter.split(X, y))\n",
    "\n",
    "selector = RFE(DecisionTreeClassifier(), step=5, n_features_to_select=25)\n",
    "\n",
    "#featuer selection via recussive feature elemination \n",
    "selector= selector.fit(pd.DataFrame(X[train_index, :], columns=feature_names_all).fillna(0), \n",
    "                               y[train_index])\n",
    "\n",
    "support_index = selector.get_support()\n",
    "feature_names = feature_names_all[support_index]\n",
    "\n",
    "X_train = df.iloc[train_index, :].loc[:, feature_names] \n",
    "X_test = df.iloc[test_index, :].loc[:, feature_names] \n",
    "y_train = y[train_index]\n",
    "y_test = y[test_index]\n",
    "\n",
    "feature_names = list(X_train.columns)\n",
    "print(F'Selected Feature Names {feature_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f1d22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "234a5972",
   "metadata": {},
   "source": [
    "#### Modeliing Fitting Using AutoML\n",
    "Searchs through models to find best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "automl = AutoMLSearch(X_train=X_train, y_train=y_train, problem_type='binary')\n",
    "with  warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    automl.search()\n",
    "model = automl.best_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e5f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95fa2c0f",
   "metadata": {},
   "source": [
    "#### Model Performance\n",
    "Calcuates Model Peformace on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02627db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts the test data\n",
    "test_preds = model.predict_proba(X_test).iloc[:, 1]\n",
    "test_pred_labels = model.predict(X_test)\n",
    "\n",
    "# calcuates metrics on test data\n",
    "test_f1 = f1_score(y_test, test_pred_labels)\n",
    "test_acc_balanced = balanced_accuracy_score(y_test, test_pred_labels)\n",
    "test_acc = accuracy_score(y_test, test_pred_labels)\n",
    "test_precision = precision_score(y_test, test_pred_labels)\n",
    "test_recall = recall_score(y_test, test_pred_labels)\n",
    "test_auc_score = roc_auc_score(y[test_index], test_preds)\n",
    "print(F'roc_auc_score: {test_auc_score } on test')\n",
    "\n",
    "## predicts the training data \n",
    "train_preds = model.predict_proba(X_train).iloc[:, 1]\n",
    "train_pred_labels = model.predict(X_train)\n",
    "\n",
    "# calculates metrics on training data \n",
    "train_f1 = f1_score(y_train, train_pred_labels)\n",
    "train_acc_balanced = balanced_accuracy_score(y_train, train_pred_labels)\n",
    "train_acc = accuracy_score(y_train, train_pred_labels)\n",
    "train_precision = precision_score(y_train, train_pred_labels)\n",
    "train_recall = recall_score(y_train, train_pred_labels)\n",
    "train_auc_score = roc_auc_score(y_train, train_preds)\n",
    "print(F'roc_auc_score: {train_auc_score} on train')\n",
    "\n",
    "# gets params Artifacts for logging mlflow model\n",
    "n_cases = np.sum(y == 1)\n",
    "n_controls = np.sum(y == 0)\n",
    "n_train_obs = X_train.shape[0]\n",
    "n_test_obs = X_test.shape[0]\n",
    "n_features = X_train.shape[1]\n",
    "train_label_prob = y_train.mean()\n",
    "test_label_prob = y_test.mean()\n",
    "desc = str(model.describe())\n",
    "model_type = type(model)\n",
    "split_type = type(splitter)\n",
    "input_example = X_train.head().fillna(0)\n",
    "signature = infer_signature(X_train.head().fillna(0), model.predict_proba(X_train.head().fillna(0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474481a9",
   "metadata": {},
   "source": [
    "#### Feature Importance\n",
    "save feature importance to a dictionary for later logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a28c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = model.feature_importance.set_index('feature')\n",
    "\n",
    "# dumps feature importance to a dictionary for logging as an artifact\n",
    "imp_dict = imp.to_dict()['importance']\n",
    "imp_json_path = 'feature_importance.json'\n",
    "with open(imp_json_path, 'w') as f:\n",
    "    json.dump(imp_dict,f)\n",
    "\n",
    "imp.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669a0c3",
   "metadata": {},
   "source": [
    "#### Model Tracking\n",
    "Uses an mlflow tracking server to save the model, parameters and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e26fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_path = 'Model'\n",
    "data_grain = 'HADM_ID'\n",
    "label_name = 'HOSPITAL_EXPIRE_FLAG'\n",
    "data_source = 'PhysioMimicIII'\n",
    "run_name = 'evalML_rfe'\n",
    "tracking_uri = \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "experiment_id=1\n",
    "with mlflow.start_run(run_name=run_name as run:\n",
    "    \n",
    "    tracking_uri = mlflow.get_tracking_uri()\n",
    "    artifact_uri = mlflow.get_artifact_uri()\n",
    "    print(\"Tracking uri: {}\".format(tracking_uri))\n",
    "    print(\"Artifact uri: {}\".format(artifact_uri))\n",
    "    mlflow.sklearn.log_model(model,\n",
    "                         artifact_path=artifact_path, \n",
    "                         signature=signature,\n",
    "                         input_example=input_example\n",
    "                        )\n",
    "    mlflow.log_artifact(imp_json_path)\n",
    "    mlflow.log_artifact(data_stats_path)\n",
    "    mlflow.log_param('data_source', data_source)\n",
    "    mlflow.log_param('label_name', label_name)\n",
    "    mlflow.log_param('data_grain', data_grain)\n",
    "    mlflow.log_param('n_cases', n_cases)\n",
    "    mlflow.log_param('n_controls', n_controls)\n",
    "    mlflow.log_param('n_train_obs', n_train_obs)\n",
    "    mlflow.log_param('n_test_obs', n_test_obs)\n",
    "    mlflow.log_param('n_features', n_features)\n",
    "    mlflow.log_param('train_label_prob', train_label_prob)\n",
    "    mlflow.log_param('test_label_prob', test_label_prob)\n",
    "    mlflow.log_param('desc', desc)\n",
    "    mlflow.log_param('model_type',model_type)\n",
    "    mlflow.log_param('split_type',split_type)\n",
    "    mlflow.log_param('feature_selection', type(selector))\n",
    "    mlflow.log_metric('train_f1', train_f1)\n",
    "    mlflow.log_metric('train_acc_balanced', train_acc_balanced)\n",
    "    mlflow.log_metric('train_acc', train_acc)\n",
    "    mlflow.log_metric('train_precision', train_precision)\n",
    "    mlflow.log_metric('train_recall', train_recall)\n",
    "    mlflow.log_metric('train_auc_score', train_auc_score)\n",
    "    mlflow.log_metric('test_f1', test_f1)\n",
    "    mlflow.log_metric('test_acc_balanced', test_acc_balanced)\n",
    "    mlflow.log_metric('test_acc', test_acc)\n",
    "    mlflow.log_metric('test_precision', test_precision)\n",
    "    mlflow.log_metric('test_recall', test_recall)\n",
    "    mlflow.log_metric('test_auc_score', test_auc_score)\n",
    "    run_id = run.info.run_id\n",
    "    experiment_id = run.info.experiment_id \n",
    "    mlflow.end_run()\n",
    "    print(F'logging experiment_id: \"{experiment_id}\" run_id :\"{run_id}\" completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f5a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db431b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
