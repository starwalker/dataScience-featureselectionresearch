{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "732a42d6",
   "metadata": {},
   "source": [
    "## Hosptial Mortality Classifcation\n",
    "this notebookes creates classifers that predict probablity that a patient died in the hospital based on lab values. It uses Phyisio Mimic III as a data source and uses the python evalML to evaluate classifers. m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae7ea522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_validate,  StratifiedKFold\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from evalml.automl import AutoMLSearch\n",
    "import evalml\n",
    "import os\n",
    "import re\n",
    "import mlflow\n",
    "from evalml.model_understanding.prediction_explanations import explain_predictions\n",
    "from mlflow.models.signature import infer_signature\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from prince import MCA\n",
    "\n",
    "MAX_MEMORY = \"32g\"\n",
    "data_dir = os.getenv('PHYSIO_HOME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a9bf6",
   "metadata": {},
   "source": [
    "#### Data Loading\n",
    "Data is loaded from Phyiso MimiIII amd saved as paquet to pyspark data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7532a1cf",
   "metadata": {},
   "source": [
    "#### Data Egneineering \n",
    "creates a features data frame using max and min lab values during hospital stays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "212932f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n_rows: 58144, n_features: 200, label_prob 0.1\n",
      "features: ['% Hemoglobin A1c_max' '% Hemoglobin A1c_min'\n",
      " 'Alanine Aminotransferase (ALT)_max' 'Alanine Aminotransferase (ALT)_min'\n",
      " 'Albumin_max' 'Albumin_min' 'Alkaline Phosphatase_max'\n",
      " 'Alkaline Phosphatase_min' 'Alveolar-arterial Gradient_max'\n",
      " 'Alveolar-arterial Gradient_min' 'Amylase_max' 'Amylase_min'\n",
      " 'Anion Gap_max' 'Anion Gap_min' 'Asparate Aminotransferase (AST)_max'\n",
      " 'Asparate Aminotransferase (AST)_min' 'Atypical Lymphocytes_max'\n",
      " 'Atypical Lymphocytes_min' 'Bands_max' 'Bands_min' 'Base Excess_max'\n",
      " 'Base Excess_min' 'Basophils_max' 'Basophils_min' 'Bicarbonate_max'\n",
      " 'Bicarbonate_min' 'Bilirubin, Direct_max' 'Bilirubin, Direct_min'\n",
      " 'Bilirubin, Indirect_max' 'Bilirubin, Indirect_min'\n",
      " 'Bilirubin, Total_max' 'Bilirubin, Total_min' 'CK-MB Index_max'\n",
      " 'CK-MB Index_min' 'Calcium, Total_max' 'Calcium, Total_min'\n",
      " 'Calculated Total CO2_max' 'Calculated Total CO2_min' 'Chloride_max'\n",
      " 'Chloride_min' 'Chloride, Whole Blood_max' 'Chloride, Whole Blood_min'\n",
      " 'Cholesterol Ratio (Total/HDL)_max' 'Cholesterol Ratio (Total/HDL)_min'\n",
      " 'Cholesterol, HDL_max' 'Cholesterol, HDL_min'\n",
      " 'Cholesterol, LDL, Calculated_max' 'Cholesterol, LDL, Calculated_min'\n",
      " 'Cholesterol, Total_max' 'Cholesterol, Total_min' 'Cortisol_max'\n",
      " 'Cortisol_min' 'Creatine Kinase (CK)_max' 'Creatine Kinase (CK)_min'\n",
      " 'Creatine Kinase, MB Isoenzyme_max' 'Creatine Kinase, MB Isoenzyme_min'\n",
      " 'Creatinine_max' 'Creatinine_min' 'Creatinine, Urine_max'\n",
      " 'Creatinine, Urine_min' 'Eosinophils_max' 'Eosinophils_min'\n",
      " 'Epithelial Cells_max' 'Epithelial Cells_min' 'Ferritin_max'\n",
      " 'Ferritin_min' 'Fibrinogen, Functional_max' 'Fibrinogen, Functional_min'\n",
      " 'Free Calcium_max' 'Free Calcium_min' 'Glucose_max' 'Glucose_min'\n",
      " 'Granulocyte Count_max' 'Granulocyte Count_min' 'Hematocrit_max'\n",
      " 'Hematocrit_min' 'Hematocrit, Calculated_max'\n",
      " 'Hematocrit, Calculated_min' 'Hemoglobin_max' 'Hemoglobin_min'\n",
      " 'INR(PT)_max' 'INR(PT)_min' 'Iron_max' 'Iron_min'\n",
      " 'Iron Binding Capacity, Total_max' 'Iron Binding Capacity, Total_min'\n",
      " 'Ketone_max' 'Ketone_min' 'Lactate_max' 'Lactate_min'\n",
      " 'Lactate Dehydrogenase (LD)_max' 'Lactate Dehydrogenase (LD)_min'\n",
      " 'Lipase_max' 'Lipase_min' 'Lymphocytes_max' 'Lymphocytes_min' 'MCH_max'\n",
      " 'MCH_min' 'MCHC_max' 'MCHC_min' 'MCV_max' 'MCV_min' 'Magnesium_max'\n",
      " 'Magnesium_min' 'Metamyelocytes_max' 'Metamyelocytes_min' 'Monocytes_max'\n",
      " 'Monocytes_min' 'Myelocytes_max' 'Myelocytes_min' 'Neutrophils_max'\n",
      " 'Neutrophils_min' 'Nucleated Red Cells_max' 'Nucleated Red Cells_min'\n",
      " 'O2 Flow_max' 'O2 Flow_min' 'Osmolality, Measured_max'\n",
      " 'Osmolality, Measured_min' 'Osmolality, Urine_max'\n",
      " 'Osmolality, Urine_min' 'Oxygen_max' 'Oxygen_min' 'Oxygen Saturation_max'\n",
      " 'Oxygen Saturation_min' 'PEEP_max' 'PEEP_min' 'PT_max' 'PT_min' 'PTT_max'\n",
      " 'PTT_min' 'Phenytoin_max' 'Phenytoin_min' 'Phosphate_max' 'Phosphate_min'\n",
      " 'Platelet Count_max' 'Platelet Count_min' 'Polys_max' 'Polys_min'\n",
      " 'Potassium_max' 'Potassium_min' 'Potassium, Urine_max'\n",
      " 'Potassium, Urine_min' 'Potassium, Whole Blood_max'\n",
      " 'Potassium, Whole Blood_min' 'Protein_max' 'Protein_min'\n",
      " 'Protein, Total_max' 'Protein, Total_min' 'RBC_max' 'RBC_min' 'RDW_max'\n",
      " 'RDW_min' 'Red Blood Cells_max' 'Red Blood Cells_min' 'Required O2_max'\n",
      " 'Required O2_min' 'Sodium_max' 'Sodium_min' 'Sodium, Urine_max'\n",
      " 'Sodium, Urine_min' 'Sodium, Whole Blood_max' 'Sodium, Whole Blood_min'\n",
      " 'Specific Gravity_max' 'Specific Gravity_min' 'Temperature_max'\n",
      " 'Temperature_min' 'Thyroid Stimulating Hormone_max'\n",
      " 'Thyroid Stimulating Hormone_min' 'Tidal Volume_max' 'Tidal Volume_min'\n",
      " 'Transferrin_max' 'Transferrin_min' 'Triglycerides_max'\n",
      " 'Triglycerides_min' 'Troponin T_max' 'Troponin T_min' 'Urea Nitrogen_max'\n",
      " 'Urea Nitrogen_min' 'Urea Nitrogen, Urine_max' 'Urea Nitrogen, Urine_min'\n",
      " 'Uric Acid_max' 'Uric Acid_min' 'Urobilinogen_max' 'Urobilinogen_min'\n",
      " 'Vancomycin_max' 'Vancomycin_min' 'Vitamin B12_max' 'Vitamin B12_min'\n",
      " 'WBC_max' 'WBC_min' 'White Blood Cells_max' 'White Blood Cells_min'\n",
      " 'pCO2_max' 'pCO2_min' 'pH_max' 'pH_min' 'pO2_max' 'pO2_min' 'tacroFK_max'\n",
      " 'tacroFK_min']\n"
     ]
    }
   ],
   "source": [
    "# reads all the csvs and writes them to parquet filesspark = SparkSession.builder \\\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HostpitalMortalityClassifier\") \\\n",
    "    .config(\"spark.executor.memory\", MAX_MEMORY) \\\n",
    "    .config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "LABEVENTS =  spark.read.parquet(data_dir + '/LABEVENTS.parquet')\n",
    "D_LABITEMS =  spark.read.parquet(data_dir + '/D_LABITEMS.parquet')\n",
    "ADMISSIONS =   spark.read.parquet(data_dir + '/ADMISSIONS.parquet')\n",
    "\n",
    "\n",
    "# sets the number of features to section by frequency\n",
    "n_features = 100\n",
    "\n",
    "# gets the top n_features most frequent features \n",
    "top_features = LABEVENTS\\\n",
    "                .join(D_LABITEMS, on = 'ITEMID', how='inner')\\\n",
    "                .dropna(subset=['VALUENUM'])\\\n",
    "                .groupby('LABEL')\\\n",
    "                .count().sort('count', ascending=False)\\\n",
    "                .limit(n_features).drop('count')\n",
    "\n",
    "\n",
    "## Data Transformations \n",
    "## gets the max and min value from the top n_features\n",
    "## groups by hospital admit id\n",
    "## creates a flag where the patient died \"Expired\" in the hosptial                                        \n",
    "data = LABEVENTS\\\n",
    ".join(D_LABITEMS, on = 'ITEMID', how='inner')\\\n",
    ".join(top_features, on='label', how='inner')\\\n",
    ".dropna(subset=['VALUENUM'])\\\n",
    ".groupby('HADM_ID')\\\n",
    ".pivot('LABEL')\\\n",
    ".agg(max('VALUENUM').alias('max'), min('VALUENUM').alias('min'))\\\n",
    ".join(ADMISSIONS.select('HADM_ID', col('HOSPITAL_EXPIRE_FLAG').alias('label')), on='HADM_ID', how='inner')\\\n",
    ".filter('label in (0,1)')\n",
    "\n",
    "## data Extraction to Pandas\n",
    "df = data.toPandas().set_index('HADM_ID')\n",
    "\n",
    "## create arrays for training model \n",
    "y = df.loc[:, 'label'].values\n",
    "X = df.drop('label', axis=1).values\n",
    "\n",
    "n_rows = X.shape[0]\n",
    "n_features = X.shape[1]\n",
    "feature_names_all = np.array(list(df.drop('label', axis=1).columns))\n",
    "label_prob = y.mean()\n",
    "print(F' n_rows: {n_rows}, n_features: {n_features}, label_prob {np.round(label_prob , 3)}')\n",
    "print(F'features: {feature_names_all}')\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2521b24",
   "metadata": {},
   "source": [
    "#### Basic Data Statics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48138e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Hemoglobin A1c_max</th>\n",
       "      <th>% Hemoglobin A1c_min</th>\n",
       "      <th>Alanine Aminotransferase (ALT)_max</th>\n",
       "      <th>Alanine Aminotransferase (ALT)_min</th>\n",
       "      <th>Albumin_max</th>\n",
       "      <th>Albumin_min</th>\n",
       "      <th>Alkaline Phosphatase_max</th>\n",
       "      <th>Alkaline Phosphatase_min</th>\n",
       "      <th>Alveolar-arterial Gradient_max</th>\n",
       "      <th>Alveolar-arterial Gradient_min</th>\n",
       "      <th>...</th>\n",
       "      <th>White Blood Cells_min</th>\n",
       "      <th>pCO2_max</th>\n",
       "      <th>pCO2_min</th>\n",
       "      <th>pH_max</th>\n",
       "      <th>pH_min</th>\n",
       "      <th>pO2_max</th>\n",
       "      <th>pO2_min</th>\n",
       "      <th>tacroFK_max</th>\n",
       "      <th>tacroFK_min</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6614.000000</td>\n",
       "      <td>6614.000000</td>\n",
       "      <td>33661.000000</td>\n",
       "      <td>33661.000000</td>\n",
       "      <td>30996.000000</td>\n",
       "      <td>30996.000000</td>\n",
       "      <td>33573.000000</td>\n",
       "      <td>33573.000000</td>\n",
       "      <td>9884.000000</td>\n",
       "      <td>9884.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>56990.000000</td>\n",
       "      <td>37347.000000</td>\n",
       "      <td>37347.000000</td>\n",
       "      <td>47548.000000</td>\n",
       "      <td>47548.000000</td>\n",
       "      <td>37350.000000</td>\n",
       "      <td>37350.000000</td>\n",
       "      <td>921.000000</td>\n",
       "      <td>921.000000</td>\n",
       "      <td>58144.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.630215</td>\n",
       "      <td>6.614914</td>\n",
       "      <td>156.416149</td>\n",
       "      <td>42.653828</td>\n",
       "      <td>3.373439</td>\n",
       "      <td>3.013466</td>\n",
       "      <td>150.903524</td>\n",
       "      <td>101.232240</td>\n",
       "      <td>475.819102</td>\n",
       "      <td>412.899332</td>\n",
       "      <td>...</td>\n",
       "      <td>8.319279</td>\n",
       "      <td>51.336493</td>\n",
       "      <td>35.295204</td>\n",
       "      <td>7.264455</td>\n",
       "      <td>5.964260</td>\n",
       "      <td>256.436573</td>\n",
       "      <td>85.320214</td>\n",
       "      <td>14.397611</td>\n",
       "      <td>4.427904</td>\n",
       "      <td>0.100182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.778103</td>\n",
       "      <td>1.775684</td>\n",
       "      <td>704.995144</td>\n",
       "      <td>163.113849</td>\n",
       "      <td>0.662730</td>\n",
       "      <td>0.747922</td>\n",
       "      <td>187.566340</td>\n",
       "      <td>98.089175</td>\n",
       "      <td>135.059334</td>\n",
       "      <td>132.920845</td>\n",
       "      <td>...</td>\n",
       "      <td>6.470020</td>\n",
       "      <td>16.686125</td>\n",
       "      <td>9.421851</td>\n",
       "      <td>0.709379</td>\n",
       "      <td>1.015657</td>\n",
       "      <td>148.659425</td>\n",
       "      <td>63.776929</td>\n",
       "      <td>7.338076</td>\n",
       "      <td>2.601365</td>\n",
       "      <td>0.300246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-22.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.600000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.350000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>421.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>7.440000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.900000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>590.000000</td>\n",
       "      <td>524.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.700000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>18.300000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>25460.000000</td>\n",
       "      <td>7035.000000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>4695.000000</td>\n",
       "      <td>3658.000000</td>\n",
       "      <td>794.000000</td>\n",
       "      <td>726.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1914.000000</td>\n",
       "      <td>630.000000</td>\n",
       "      <td>93.200000</td>\n",
       "      <td>25.700000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       % Hemoglobin A1c_max  % Hemoglobin A1c_min  \\\n",
       "count           6614.000000           6614.000000   \n",
       "mean               6.630215              6.614914   \n",
       "std                1.778103              1.775684   \n",
       "min                3.800000              3.800000   \n",
       "25%                5.600000              5.600000   \n",
       "50%                6.000000              6.000000   \n",
       "75%                6.900000              6.900000   \n",
       "max               22.000000             22.000000   \n",
       "\n",
       "       Alanine Aminotransferase (ALT)_max  Alanine Aminotransferase (ALT)_min  \\\n",
       "count                        33661.000000                        33661.000000   \n",
       "mean                           156.416149                           42.653828   \n",
       "std                            704.995144                          163.113849   \n",
       "min                              0.000000                            0.000000   \n",
       "25%                             18.000000                           13.000000   \n",
       "50%                             30.000000                           21.000000   \n",
       "75%                             66.000000                           35.000000   \n",
       "max                          25460.000000                         7035.000000   \n",
       "\n",
       "        Albumin_max   Albumin_min  Alkaline Phosphatase_max  \\\n",
       "count  30996.000000  30996.000000              33573.000000   \n",
       "mean       3.373439      3.013466                150.903524   \n",
       "std        0.662730      0.747922                187.566340   \n",
       "min        1.000000      0.900000                  3.000000   \n",
       "25%        2.900000      2.500000                 69.000000   \n",
       "50%        3.400000      3.000000                 96.000000   \n",
       "75%        3.800000      3.600000                156.000000   \n",
       "max        6.900000      5.700000               4695.000000   \n",
       "\n",
       "       Alkaline Phosphatase_min  Alveolar-arterial Gradient_max  \\\n",
       "count              33573.000000                     9884.000000   \n",
       "mean                 101.232240                      475.819102   \n",
       "std                   98.089175                      135.059334   \n",
       "min                    0.000000                        6.000000   \n",
       "25%                   57.000000                      380.000000   \n",
       "50%                   76.000000                      510.000000   \n",
       "75%                  108.000000                      590.000000   \n",
       "max                 3658.000000                      794.000000   \n",
       "\n",
       "       Alveolar-arterial Gradient_min  ...  White Blood Cells_min  \\\n",
       "count                     9884.000000  ...           56990.000000   \n",
       "mean                       412.899332  ...               8.319279   \n",
       "std                        132.920845  ...               6.470020   \n",
       "min                        -22.000000  ...               0.000000   \n",
       "25%                        310.000000  ...               5.400000   \n",
       "50%                        421.000000  ...               7.200000   \n",
       "75%                        524.000000  ...               9.700000   \n",
       "max                        726.000000  ...             378.000000   \n",
       "\n",
       "           pCO2_max      pCO2_min        pH_max        pH_min       pO2_max  \\\n",
       "count  37347.000000  37347.000000  47548.000000  47548.000000  37350.000000   \n",
       "mean      51.336493     35.295204      7.264455      5.964260    256.436573   \n",
       "std       16.686125      9.421851      0.709379      1.015657    148.659425   \n",
       "min        8.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "25%       42.000000     30.000000      7.350000      5.000000    124.000000   \n",
       "50%       48.000000     34.000000      7.440000      5.500000    230.000000   \n",
       "75%       56.000000     39.000000      7.500000      7.000000    390.000000   \n",
       "max      247.000000    165.000000     10.000000      9.000000   1914.000000   \n",
       "\n",
       "            pO2_min  tacroFK_max  tacroFK_min         label  \n",
       "count  37350.000000   921.000000   921.000000  58144.000000  \n",
       "mean      85.320214    14.397611     4.427904      0.100182  \n",
       "std       63.776929     7.338076     2.601365      0.300246  \n",
       "min        0.000000     1.200000     1.200000      0.000000  \n",
       "25%       46.000000     9.500000     2.700000      0.000000  \n",
       "50%       70.000000    14.100000     3.800000      0.000000  \n",
       "75%      100.000000    18.300000     5.500000      0.000000  \n",
       "max      630.000000    93.200000    25.700000      1.000000  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stats_path = 'data_stats.csv'\n",
    "data_stats = df.describe()\n",
    "data_stats.to_csv(data_stats_path)\n",
    "data_stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6754a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from FeatureSelectors.feature_extraction import IsObserved\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from FeatureSelectors.feature_extraction import Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b4546",
   "metadata": {},
   "source": [
    "#### Data Splitting\n",
    "Data splitting via Statified Shuffle Split\n",
    "\n",
    "#### Feature Selection pyImpetous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "understood-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "n_mca_comps = 10\n",
    "\n",
    "splitter = StratifiedKFold(shuffle=True)\n",
    "train_index, test_index = next(splitter.split(X, y))\n",
    "\n",
    "## tran\n",
    "obs_pipe = Pipeline(steps=[('Isob', IsObserved()), ('mca', MCA(n_mca_comps))])\\\n",
    ".fit(df.iloc[train_index, :].loc[:, feature_names_all])\n",
    "\n",
    "num_pipe = Pipeline(steps=[('scaler', Scaler()), ('imp', SimpleImputer())])\\\n",
    ".fit(df.iloc[train_index, :].loc[:, feature_names_all].values)\n",
    "\n",
    "\n",
    "indicies_all = np.arange(len(feature_names_all))\n",
    "\n",
    "transformers = [('obs',obs_pipe, indicies_all), ('imp', num_pipe, indicies_all)]   \n",
    "\n",
    "\n",
    "pipe = ColumnTransformer(transformers).fit(df.iloc[train_index, :].loc[:, feature_names_all].values )\n",
    "\n",
    "X_train = pipe.transform(df.iloc[train_index, :].loc[:, feature_names_all] )\n",
    "X_test =  pipe.transform(df.iloc[test_index, :].loc[:, feature_names_all] )\n",
    "y_train = y[train_index]\n",
    "y_test = y[test_index]\n",
    "\n",
    "feature_names_transformed_all = np.array(['mca_'+ str(i) for i in range(n_mca_comps)] + list(feature_names_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "pleasant-mounting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"concat[[('Isob', IsObserved()), ('mca', MCA(n_components=10))],  [('scaler', Scaler()), ('imp', SimpleImputer())] ]\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_desc = F'concat[{pipe.transformers[0][1].steps},  {pipe.transformers[1][1].steps} ]' \n",
    "pipeline_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "562dfc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FeatureSelectors.Distancecorrelation import Selector\n",
    "selector = Selector()\n",
    "selector= selector.fit(X_train, y_train)\n",
    "support_index = selector.get_support()\n",
    "best_features = feature_names_transformed_all[support_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f1d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234a5972",
   "metadata": {},
   "source": [
    "#### Modeliing Fitting Using AutoML\n",
    "Searchs through models to find best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a6a0acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default limit of max_batches=1.\n",
      "\n",
      "Generating pipelines to search over...\n",
      "8 pipelines ready for search.\n",
      "\n",
      "*****************************\n",
      "* Beginning pipeline search *\n",
      "*****************************\n",
      "\n",
      "Optimizing for Log Loss Binary. \n",
      "Lower score is better.\n",
      "\n",
      "Using SequentialEngine to train and score pipelines.\n",
      "Searching up to 1 batches for a total of 9 pipelines. \n",
      "Allowed model families: decision_tree, xgboost, catboost, random_forest, extra_trees, lightgbm, linear_model\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e840cdc5254ce6a21ab6219cfeaed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Baseline Pipeline: Mode Baseline Binary Classification Pipeline\n",
      "Mode Baseline Binary Classification Pipeline:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 3.460\n",
      "\n",
      "*****************************\n",
      "* Evaluating Batch Number 1 *\n",
      "*****************************\n",
      "\n",
      "Elastic Net Classifier w/ Imputer + Undersampler + Standard Scaler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.273\n",
      "Decision Tree Classifier w/ Imputer + Undersampler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.309\n",
      "Random Forest Classifier w/ Imputer + Undersampler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.248\n",
      "LightGBM Classifier w/ Imputer + Undersampler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.186\n",
      "Logistic Regression Classifier w/ Imputer + Undersampler + Standard Scaler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.238\n",
      "[10:34:36] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:34:40] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:34:43] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost Classifier w/ Imputer + Undersampler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.189\n",
      "Extra Trees Classifier w/ Imputer + Undersampler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.296\n",
      "CatBoost Classifier w/ Imputer + Undersampler:\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean Log Loss Binary: 0.493\n",
      "\n",
      "Search finished after 01:11            \n",
      "Best pipeline: LightGBM Classifier w/ Imputer + Undersampler\n",
      "Best pipeline Log Loss Binary: 0.185922\n"
     ]
    }
   ],
   "source": [
    "\n",
    "automl = AutoMLSearch(X_train=pd.DataFrame(X_train,columns=feature_names_transformed_all).loc[:, best_features], y_train=y_train, problem_type='binary')\n",
    "with  warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    automl.search()\n",
    "model = automl.best_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e5f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95fa2c0f",
   "metadata": {},
   "source": [
    "#### Model Performance\n",
    "Calcuates Model Peformace on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02627db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score: 0.9399788032707275 on test\n",
      "roc_auc_score: 0.9753676882636406 on train\n",
      "\n",
      "*************************************************\n",
      "* LightGBM Classifier w/ Imputer + Undersampler *\n",
      "*************************************************\n",
      "\n",
      "Problem Type: binary\n",
      "Model Family: LightGBM\n",
      "Number of features: 133\n",
      "\n",
      "Pipeline Steps\n",
      "==============\n",
      "1. Imputer\n",
      "\t * categorical_impute_strategy : most_frequent\n",
      "\t * numeric_impute_strategy : mean\n",
      "\t * categorical_fill_value : None\n",
      "\t * numeric_fill_value : None\n",
      "2. Undersampler\n",
      "\t * sampling_ratio : 0.25\n",
      "\t * min_samples : 100\n",
      "\t * min_percentage : 0.1\n",
      "\t * sampling_ratio_dict : None\n",
      "3. LightGBM Classifier\n",
      "\t * boosting_type : gbdt\n",
      "\t * learning_rate : 0.1\n",
      "\t * n_estimators : 100\n",
      "\t * max_depth : 0\n",
      "\t * num_leaves : 31\n",
      "\t * min_child_samples : 20\n",
      "\t * n_jobs : -1\n",
      "\t * bagging_freq : 0\n",
      "\t * bagging_fraction : 0.9\n"
     ]
    }
   ],
   "source": [
    "# predicts the test data\n",
    "test_preds = model.predict_proba(pd.DataFrame(X_test,columns=feature_names_transformed_all).loc[:, best_features]).iloc[:, 1]\n",
    "test_pred_labels = model.predict(pd.DataFrame(X_test,columns=feature_names_transformed_all).loc[:, best_features])\n",
    "\n",
    "## predicts the training data \n",
    "train_preds = model.predict_proba(pd.DataFrame(X_train,columns=feature_names_transformed_all).loc[:, best_features]).iloc[:, 1]\n",
    "train_pred_labels = model.predict(pd.DataFrame(X_train,columns=feature_names_transformed_all).loc[:, best_features])\n",
    "\n",
    "\n",
    "\n",
    "# calcuates metrics on test data\n",
    "test_f1 = f1_score(y_test, test_pred_labels)\n",
    "test_acc_balanced = balanced_accuracy_score(y_test, test_pred_labels)\n",
    "test_acc = accuracy_score(y_test, test_pred_labels)\n",
    "test_precision = precision_score(y_test, test_pred_labels)\n",
    "test_recall = recall_score(y_test, test_pred_labels)\n",
    "test_auc_score = roc_auc_score(y[test_index], test_preds)\n",
    "print(F'roc_auc_score: {test_auc_score } on test')\n",
    "\n",
    "\n",
    "# calculates metrics on training data \n",
    "train_f1 = f1_score(y_train, train_pred_labels)\n",
    "train_acc_balanced = balanced_accuracy_score(y_train, train_pred_labels)\n",
    "train_acc = accuracy_score(y_train, train_pred_labels)\n",
    "train_precision = precision_score(y_train, train_pred_labels)\n",
    "train_recall = recall_score(y_train, train_pred_labels)\n",
    "train_auc_score = roc_auc_score(y_train, train_preds)\n",
    "print(F'roc_auc_score: {train_auc_score} on train')\n",
    "\n",
    "# gets params Artifacts for logging mlflow model\n",
    "n_cases = np.sum(y == 1)\n",
    "n_controls = np.sum(y == 0)\n",
    "n_train_obs = X_train.shape[0]\n",
    "n_test_obs = X_test.shape[0]\n",
    "\n",
    "train_label_prob = y_train.mean()\n",
    "test_label_prob = y_test.mean()\n",
    "desc = str(model.describe())\n",
    "model_type = type(model)\n",
    "split_type = type(splitter)\n",
    "input_example = pd.DataFrame(X_train,columns=feature_names_transformed_all).loc[:, best_features].head(5).fillna(0)\n",
    "signature = infer_signature(input_example,  model.predict_proba(input_example))\n",
    "n_features =input_example.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474481a9",
   "metadata": {},
   "source": [
    "#### Feature Importance\n",
    "save feature importance to a dictionary for later logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51a28c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bicarbonate_max</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose_min</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urea Nitrogen_min</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pCO2_max</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sodium_max</th>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   importance\n",
       "feature                      \n",
       "Bicarbonate_max           147\n",
       "Glucose_min               128\n",
       "Urea Nitrogen_min         112\n",
       "pCO2_max                  105\n",
       "Sodium_max                103"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = model.feature_importance.set_index('feature')\n",
    "\n",
    "# dumps feature importance to a dictionary for logging as an artifact\n",
    "imp_dict = imp.to_dict()['importance']\n",
    "imp_json_path = 'feature_importance.json'\n",
    "with open(imp_json_path, 'w') as f:\n",
    "    json.dump(imp_dict,f)\n",
    "\n",
    "imp.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8669a0c3",
   "metadata": {},
   "source": [
    "#### Model Tracking\n",
    "Uses an mlflow tracking server to save the model, parameters and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "895e26fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking uri: http://localhost:5000\n",
      "Artifact uri: ./mlruns/0/0f377876f9344b48994db7873e1d3d8b/artifacts\n",
      "logging experiment_id: \"0\" run_id :\"0f377876f9344b48994db7873e1d3d8b\" completed\n"
     ]
    }
   ],
   "source": [
    "artifact_path = 'Model'\n",
    "data_grain = 'HADM_ID'\n",
    "label_name = 'HOSPITAL_EXPIRE_FLAG'\n",
    "data_source = 'PhysioMimicIII'\n",
    "run_name = 'evalML_dcor w_isObeserved'\n",
    "tracking_uri = \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "experiment_id=1\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    \n",
    "    tracking_uri = mlflow.get_tracking_uri()\n",
    "    artifact_uri = mlflow.get_artifact_uri()\n",
    "    print(\"Tracking uri: {}\".format(tracking_uri))\n",
    "    print(\"Artifact uri: {}\".format(artifact_uri))\n",
    "    mlflow.sklearn.log_model(model,\n",
    "                         artifact_path=artifact_path, \n",
    "                         signature=signature,\n",
    "                         input_example=input_example\n",
    "                        )\n",
    "    mlflow.log_artifact(imp_json_path)\n",
    "    mlflow.log_artifact(data_stats_path)\n",
    "    mlflow.log_param('data_source', data_source)\n",
    "    mlflow.log_param('label_name', label_name)\n",
    "    mlflow.log_param('data_grain', data_grain)\n",
    "    mlflow.log_param('n_cases', n_cases)\n",
    "    mlflow.log_param('n_controls', n_controls)\n",
    "    mlflow.log_param('n_train_obs', n_train_obs)\n",
    "    mlflow.log_param('n_test_obs', n_test_obs)\n",
    "    mlflow.log_param('n_features', n_features)\n",
    "    mlflow.log_param('train_label_prob', train_label_prob)\n",
    "    mlflow.log_param('test_label_prob', test_label_prob)\n",
    "    mlflow.log_param('desc', desc)\n",
    "    mlflow.log_param('model_type',model_type)\n",
    "    mlflow.log_param('split_type',split_type)\n",
    "    mlflow.log_param('feature_selection', type(selector))\n",
    "    mlflow.log_param('pipeline_desc', pipeline_desc)\n",
    "    mlflow.log_param('pipeline_desc', pipeline_desc)\n",
    "    mlflow.log_param('importance', str(imp))\n",
    "    mlflow.log_metric('train_f1', train_f1)\n",
    "    mlflow.log_metric('train_acc_balanced', train_acc_balanced)\n",
    "    mlflow.log_metric('train_acc', train_acc)\n",
    "    mlflow.log_metric('train_precision', train_precision)\n",
    "    mlflow.log_metric('train_recall', train_recall)\n",
    "    mlflow.log_metric('train_auc_score', train_auc_score)\n",
    "    mlflow.log_metric('test_f1', test_f1)\n",
    "    mlflow.log_metric('test_acc_balanced', test_acc_balanced)\n",
    "    mlflow.log_metric('test_acc', test_acc)\n",
    "    mlflow.log_metric('test_precision', test_precision)\n",
    "    mlflow.log_metric('test_recall', test_recall)\n",
    "    mlflow.log_metric('test_auc_score', test_auc_score)\n",
    "    mlflow.log_param('features', '|'.join(imp.index))\n",
    "    run_id = run.info.run_id\n",
    "    experiment_id = run.info.experiment_id \n",
    "    mlflow.end_run()\n",
    "    print(F'logging experiment_id: \"{experiment_id}\" run_id :\"{run_id}\" completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe8f5a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                                  importance\\nfeature                                     \\nBicarbonate_max                          147\\nGlucose_min                              128\\nUrea Nitrogen_min                        112\\npCO2_max                                 105\\nSodium_max                               103\\n...                                      ...\\nProtein, Total_min                         2\\nCholesterol, LDL, Calculated_max           1\\nEpithelial Cells_min                       1\\nFerritin_min                               1\\nUrobilinogen_min                           1\\n\\n[133 rows x 1 columns]'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db431b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
